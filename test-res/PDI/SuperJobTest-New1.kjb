<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>SuperJobTest-New1</name>
    <description/>
    <extended_description/>
    <job_version/>
    <job_status>0</job_status>
  <directory>&#x2f;</directory>
  <created_user>-</created_user>
  <created_date>2012&#x2f;06&#x2f;20 15&#x3a;27&#x3a;53.216</created_date>
  <modified_user>-</modified_user>
  <modified_date>2012&#x2f;06&#x2f;20 15&#x3a;27&#x3a;53.216</modified_date>
    <parameters>
    </parameters>
  <connection>
    <name>AgileBI</name>
    <server>localhost</server>
    <type>MONETDB</type>
    <access>Native</access>
    <database>pentaho-instaview</database>
    <port>50006</port>
    <username>monetdb</username>
    <password>Encrypted 2be98afc86aa7f2e4cb14a17edb86abd8</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <read_only>true</read_only>
    <attributes>
      <attribute><code>EXTRA_OPTION_INFOBRIGHT.characterEncoding</code><attribute>UTF-8</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.defaultFetchSize</code><attribute>500</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.useCursorFetch</code><attribute>true</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>50006</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>Logoutput</name>
    <server>localhost</server>
    <type>MYSQL</type>
    <access>Native</access>
    <database>pdilog</database>
    <port>3306</port>
    <username>root</username>
    <password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>EXTRA_OPTION_MYSQL.defaultFetchSize</code><attribute>500</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.useCursorFetch</code><attribute>true</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>3306</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>STREAM_RESULTS</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>N</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>RDBMS</name>
    <server>my.hostname.com</server>
    <type>MYSQL</type>
    <access>Native</access>
    <database>test</database>
    <port>3306</port>
    <username>root</username>
    <password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>EXTRA_OPTION_MYSQL.defaultFetchSize</code><attribute>500</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.useCursorFetch</code><attribute>true</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>3306</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>STREAM_RESULTS</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>N</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
    <slaveservers>
         <slaveserver><name>di_server</name><hostname>localhost</hostname><port>9080</port><webAppName>pentaho-di</webAppName><username>joe</username><password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master></slaveserver>
         <slaveserver><name>slave_1</name><hostname>localhost</hostname><port>8082</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master></slaveserver>
         <slaveserver><name>Carte</name><hostname>localhost</hostname><port>9991</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master></slaveserver>
         <slaveserver><name>master</name><hostname>localhost</hostname><port>8081</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master></slaveserver>
         <slaveserver><name>slave_2</name><hostname>localhost</hostname><port>8083</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master></slaveserver>
    </slaveservers>
<job-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>START_JOB_ENTRY</id><enabled>N</enabled><name>START_JOB_ENTRY</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></job-log-table>
<jobentry-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>JOBENTRYNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>RESULT</id><enabled>Y</enabled><name>RESULT</name></field><field><id>NR_RESULT_ROWS</id><enabled>Y</enabled><name>NR_RESULT_ROWS</name></field><field><id>NR_RESULT_FILES</id><enabled>Y</enabled><name>NR_RESULT_FILES</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field><field><id>COPY_NR</id><enabled>N</enabled><name>COPY_NR</name></field></jobentry-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<checkpoint-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<max_nr_retries/>
<run_retry_period/>
<namespace_parameter/>
<save_parameters/>
<save_result_rows/>
<save_result_files/>
<field><id>ID_JOB_RUN</id><enabled>Y</enabled><name>ID_JOB_RUN</name></field><field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>NAMESPACE</id><enabled>Y</enabled><name>NAMESPACE</name></field><field><id>CHECKPOINT_NAME</id><enabled>Y</enabled><name>CHECKPOINT_NAME</name></field><field><id>CHECKPOINT_COPYNR</id><enabled>Y</enabled><name>CHECKPOINT_COPYNR</name></field><field><id>ATTEMPT_NR</id><enabled>Y</enabled><name>ATTEMPT_NR</name></field><field><id>JOB_RUN_START_DATE</id><enabled>Y</enabled><name>JOB_RUN_START_DATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>RESULT_XML</id><enabled>Y</enabled><name>RESULT_XML</name></field><field><id>PARAMETER_XML</id><enabled>Y</enabled><name>PARAMETER_XML</name></field></checkpoint-log-table>
   <pass_batchid>N</pass_batchid>
   <shared_objects_file/>
  <entries>
    <entry>
      <name>START</name>
      <description/>
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>0</xloc>
      <yloc>142</yloc>
      </entry>
    <entry>
      <name>Load HDFS</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;load_hdfs_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>308</xloc>
      <yloc>159</yloc>
      </entry>
    <entry>
      <name>Load HDFS Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load HDFS failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>377</xloc>
      <yloc>35</yloc>
      </entry>
    <entry>
      <name>Load HDFS Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load HDFS Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>369</xloc>
      <yloc>402</yloc>
      </entry>
    <entry>
      <name>Load Hive</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;load_hive_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>525</xloc>
      <yloc>150</yloc>
      </entry>
    <entry>
      <name>Load Hive Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load Hive Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>588</xloc>
      <yloc>39</yloc>
      </entry>
    <entry>
      <name>Load Hive Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load Hive Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>574</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>Set variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <replacevars>Y</replacevars>
      <filename>&#x24;&#x7b;Internal.Job.Filename.Directory&#x7d;&#x2f;SuperJobParameters.properties</filename>
      <file_variable_type>JVM</file_variable_type>
      <fields>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>91</xloc>
      <yloc>143</yloc>
      </entry>
    <entry>
      <name>Hadoop-InputOutput-test</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Hadoop-InputOutput-test_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1018</xloc>
      <yloc>150</yloc>
      </entry>
    <entry>
      <name>HadoopInputOutput Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hadoop-InputOutput-test Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1097</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>HadoopInputOutput Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hadoop-InputOutput-test Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1093</xloc>
      <yloc>44</yloc>
      </entry>
    <entry>
      <name>Hive1-Input</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Hive1-Input_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>Hive1Host</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>Hive1Port</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1533</xloc>
      <yloc>155</yloc>
      </entry>
    <entry>
      <name>Hive1-Input Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hive1-Input Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1621</xloc>
      <yloc>49</yloc>
      </entry>
    <entry>
      <name>Hive1-Input Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hive1-Input Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1632</xloc>
      <yloc>399</yloc>
      </entry>
    <entry>
      <name>AggregatePig</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;aggregate_pig_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2325</xloc>
      <yloc>144</yloc>
      </entry>
    <entry>
      <name>AggregatePig Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>AggregatePig Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2410</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>AggregatePig Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>AggregatePig Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2407</xloc>
      <yloc>60</yloc>
      </entry>
    <entry>
      <name>HadoopJobExecutor</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;HadoopJobExecutor_simple_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2599</xloc>
      <yloc>146</yloc>
      </entry>
    <entry>
      <name>HadoopJobExecutor Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>HadoopJobExecutor Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2690</xloc>
      <yloc>400</yloc>
      </entry>
    <entry>
      <name>HadoopJobExecutor Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>HadoopJobExecutor Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2680</xloc>
      <yloc>62</yloc>
      </entry>
    <entry>
      <name>AggregateMR</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;aggregate_mr_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2850</xloc>
      <yloc>147</yloc>
      </entry>
    <entry>
      <name>AggregateMR Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>AggregateMR Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2934</xloc>
      <yloc>398</yloc>
      </entry>
    <entry>
      <name>AggregateMR Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>AggregateMR Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2915</xloc>
      <yloc>59</yloc>
      </entry>
    <entry>
      <name>PMR - Hadoop</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Pentaho MapReduce - Hadoop - test_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3094</xloc>
      <yloc>148</yloc>
      </entry>
    <entry>
      <name>PMR - Hadoop Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hadoop Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3187</xloc>
      <yloc>398</yloc>
      </entry>
    <entry>
      <name>PMR - Hadoop Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hadoop Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3181</xloc>
      <yloc>62</yloc>
      </entry>
    <entry>
      <name>PMR - Hive1</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Pentaho MapReduce - Hive1- test_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3652</xloc>
      <yloc>159</yloc>
      </entry>
    <entry>
      <name>PMR - Hive1 Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hive1 Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3739</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>PMR - Hive1 Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hive1 Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3737</xloc>
      <yloc>68</yloc>
      </entry>
    <entry>
      <name>Load HBase</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;load_hbase_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>758</xloc>
      <yloc>153</yloc>
      </entry>
    <entry>
      <name>Load HBase Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load HBase Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>856</xloc>
      <yloc>400</yloc>
      </entry>
    <entry>
      <name>Load HBase Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Load HBase Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>841</xloc>
      <yloc>44</yloc>
      </entry>
    <entry>
      <name>HBase-InputOutput-test</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;HBase-InputOutput-test_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1267</xloc>
      <yloc>154</yloc>
      </entry>
    <entry>
      <name>HBaseInputOutput Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>HBase-InputOutput-test Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1361</xloc>
      <yloc>401</yloc>
      </entry>
    <entry>
      <name>HBaseInputOutput Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>HBase-InputOutput-test Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1342</xloc>
      <yloc>47</yloc>
      </entry>
    <entry>
      <name>PMR - HBase</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Pentaho MapReduce - HBase - test_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3365</xloc>
      <yloc>150</yloc>
      </entry>
    <entry>
      <name>PMR - HBase Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - HBase Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3460</xloc>
      <yloc>398</yloc>
      </entry>
    <entry>
      <name>PMR - HBase Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - HBase Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>3478</xloc>
      <yloc>64</yloc>
      </entry>
    <entry>
      <name>LoadHDFS evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>LoadHDFS</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>185</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>Hive2-Input</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Hive2-Input_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>Hive2Host</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>Hive2Port</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1795</xloc>
      <yloc>152</yloc>
      </entry>
    <entry>
      <name>Hive2-Input Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hive2-Input Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1882</xloc>
      <yloc>50</yloc>
      </entry>
    <entry>
      <name>Hive2-Input Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Hive2-Input Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>1896</xloc>
      <yloc>399</yloc>
      </entry>
    <entry>
      <name>Impala-Input</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Impala-Input_parameter.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>ImpalaHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>ImpalaPort</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2056</xloc>
      <yloc>149</yloc>
      </entry>
    <entry>
      <name>Impala-Input Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Impala-Input Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2139</xloc>
      <yloc>54</yloc>
      </entry>
    <entry>
      <name>Impala-Input Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Impala-Input Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>2161</xloc>
      <yloc>402</yloc>
      </entry>
    <entry>
      <name>PMR - Hive2</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Pentaho MapReduce - Hive2- test_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3919</xloc>
      <yloc>156</yloc>
      </entry>
    <entry>
      <name>PMR - Hive2 Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hive2 Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4011</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>PMR - Hive2 Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Hive2 Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4006</xloc>
      <yloc>70</yloc>
      </entry>
    <entry>
      <name>PMR - Impala</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;Pentaho MapReduce - Impala- test_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>JobTrackerPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4184</xloc>
      <yloc>156</yloc>
      </entry>
    <entry>
      <name>PMR - Impala Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Impala Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4276</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>PMR - Impala Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>PMR - Impala Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4278</xloc>
      <yloc>74</yloc>
      </entry>
    <entry>
      <name>Oozie-MapReduce</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;OozieMapReduce_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>DirPath</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>OozieURL</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5585</xloc>
      <yloc>153</yloc>
      </entry>
    <entry>
      <name>Oozie-MapReduce Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Oozie-MapReduce failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5694</xloc>
      <yloc>84</yloc>
      </entry>
    <entry>
      <name>Oozie-MapReduce Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>Oozie-MapReduce Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5707</xloc>
      <yloc>404</yloc>
      </entry>
    <entry>
      <name>SqoopImportHDFS</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;SqoopImportHDFSTest_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>HDFSHost</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>HDFSPort</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4457</xloc>
      <yloc>151</yloc>
      </entry>
    <entry>
      <name>SqoopImportHDFS Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHDFS Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4557</xloc>
      <yloc>403</yloc>
      </entry>
    <entry>
      <name>SqoopImportHDFS Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHDFS Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4564</xloc>
      <yloc>78</yloc>
      </entry>
    <entry>
      <name>SqoopImportHBase</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;SqoopImportHBaseTest_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>&#x24;&#x7b;HDFSHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;HDFSPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;ZookeeperHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;ZookeeperPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4744</xloc>
      <yloc>152</yloc>
      </entry>
    <entry>
      <name>SqoopImportHBase Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHBase Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4849</xloc>
      <yloc>81</yloc>
      </entry>
    <entry>
      <name>SqoopImportHBase Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHBase Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>4836</xloc>
      <yloc>407</yloc>
      </entry>
    <entry>
      <name>SqoopImportHive</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;SqoopImportHiveTest_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>&#x24;&#x7b;HDFSHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;HDFSPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5014</xloc>
      <yloc>154</yloc>
      </entry>
    <entry>
      <name>SqoopImportHive Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHive Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>5119</xloc>
      <yloc>83</yloc>
      </entry>
    <entry>
      <name>SqoopImportHive Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopImportHive Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>5131</xloc>
      <yloc>410</yloc>
      </entry>
    <entry>
      <name>SqoopExportHDFS</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;DirPath&#x7d;SqoopExportHDFSTest_parameter.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <force_separate_logging>N</force_separate_logging>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
            <parameter>            <name>&#x24;&#x7b;HDFSHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;HDFSPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerHost&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>            <parameter>            <name>&#x24;&#x7b;JobTrackerPort&#x7d;</name>
            <stream_name/>
            <value/>
            </parameter>      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5305</xloc>
      <yloc>151</yloc>
      </entry>
    <entry>
      <name>SqoopExportHDFS Fail Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopExportHDFS Failed&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>5403</xloc>
      <yloc>79</yloc>
      </entry>
    <entry>
      <name>SqoopExportHDFS Succeed Write</name>
      <description/>
      <type>WRITE_TO_FILE</type>
      <filename>&#x24;&#x7b;DirPath&#x7d;SuperJobLog.txt</filename>
      <createParentFolder>N</createParentFolder>
      <appendFile>Y</appendFile>
      <content>SqoopExportHDFS Succeeded&#xa;</content>
      <encoding/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>5403</xloc>
      <yloc>410</yloc>
      </entry>
    <entry>
      <name>LoadHive evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>LoadHive</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>425</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>LoadHBase evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>LoadHBase</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>659</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>HadoopInputOutput evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>HadoopInputOutput</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>913</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>HBaseInputOutput evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>HBaseInputOutput</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1163</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>Hive2Input evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>Hive2Input</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1695</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>AggregateMR evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>AggregateMR</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2757</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>Hive1Input evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>Hive1Input</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1426</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>HadoopJobExecutor evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>HadoopJobExecutor</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2486</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>PMR-HBase evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>PMR-HBase</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3257</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>PMR-Hive1 evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>PMR-Hive1</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3563</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>PMR-Impala evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>PMR-Impala</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4081</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>PMR-Hive2 evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>PMR-Hive2</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>3822</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>PMR-Hadoop evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>PMR-Hadoop</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2997</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>ImpalaInput evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>ImpalaInput</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1962</xloc>
      <yloc>248</yloc>
      </entry>
    <entry>
      <name>AggregatePig evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>AggregatePig</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>2227</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>SqoopImportHDFS evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>SqoopImportHDFS</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4356</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>SqoopImportHBase evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>SqoopImportHBase</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4628</xloc>
      <yloc>250</yloc>
      </entry>
    <entry>
      <name>SqoopExportHDFS evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>SqoopExportHDFS</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5214</xloc>
      <yloc>250</yloc>
      </entry>
    <entry>
      <name>Oozie-MapReduce evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>Oozie-MapReduce</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5480</xloc>
      <yloc>249</yloc>
      </entry>
    <entry>
      <name>SqoopImportHive evaluation</name>
      <description/>
      <type>SIMPLE_EVAL</type>
      <valuetype>variable</valuetype>
      <fieldname/>
      <variablename>SqoopImportHive</variablename>
      <fieldtype>string</fieldtype>
      <mask/>
      <comparevalue>Yes</comparevalue>
      <minvalue/>
      <maxvalue/>
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>4925</xloc>
      <yloc>250</yloc>
      </entry>
    <entry>
      <name>DUMMY</name>
      <description/>
      <type>SPECIAL</type>
      <start>N</start>
      <dummy>Y</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>5794</xloc>
      <yloc>250</yloc>
      </entry>
  </entries>
  <hops>
    <hop>
      <from>Load HDFS</from>
      <to>Load HDFS Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HDFS</from>
      <to>Load HDFS Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load Hive</from>
      <to>Load Hive Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load Hive</from>
      <to>Load Hive Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>Set variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Hadoop-InputOutput-test</from>
      <to>HadoopInputOutput Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hadoop-InputOutput-test</from>
      <to>HadoopInputOutput Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1-Input</from>
      <to>Hive1-Input Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1-Input</from>
      <to>Hive1-Input Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig</from>
      <to>AggregatePig Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig</from>
      <to>AggregatePig Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor</from>
      <to>HadoopJobExecutor Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor</from>
      <to>HadoopJobExecutor Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR</from>
      <to>AggregateMR Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR</from>
      <to>AggregateMR Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hadoop</from>
      <to>PMR - Hadoop Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hadoop</from>
      <to>PMR - Hadoop Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive1</from>
      <to>PMR - Hive1 Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive1</from>
      <to>PMR - Hive1 Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HBase</from>
      <to>Load HBase Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HBase</from>
      <to>Load HBase Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBase-InputOutput-test</from>
      <to>HBaseInputOutput Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBase-InputOutput-test</from>
      <to>HBaseInputOutput Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - HBase</from>
      <to>PMR - HBase Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - HBase</from>
      <to>PMR - HBase Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2-Input</from>
      <to>Hive2-Input Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2-Input</from>
      <to>Hive2-Input Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Impala-Input</from>
      <to>Impala-Input Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Impala-Input</from>
      <to>Impala-Input Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive2</from>
      <to>PMR - Hive2 Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive2</from>
      <to>PMR - Hive2 Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Impala</from>
      <to>PMR - Impala Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Impala</from>
      <to>PMR - Impala Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce</from>
      <to>Oozie-MapReduce Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce</from>
      <to>Oozie-MapReduce Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS</from>
      <to>SqoopImportHDFS Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS</from>
      <to>SqoopImportHDFS Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase</from>
      <to>SqoopImportHBase Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase</from>
      <to>SqoopImportHBase Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive</from>
      <to>SqoopImportHive Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive</from>
      <to>SqoopImportHive Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS</from>
      <to>SqoopExportHDFS Succeed Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS</from>
      <to>SqoopExportHDFS Fail Write</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set variables</from>
      <to>LoadHDFS evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHDFS evaluation</from>
      <to>Load HDFS</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HDFS Succeed Write</from>
      <to>LoadHive evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HDFS Fail Write</from>
      <to>LoadHive evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHDFS evaluation</from>
      <to>LoadHive evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHive evaluation</from>
      <to>Load Hive</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load Hive Succeed Write</from>
      <to>LoadHBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load Hive Fail Write</from>
      <to>LoadHBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHive evaluation</from>
      <to>LoadHBase evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HBase Fail Write</from>
      <to>HadoopInputOutput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load HBase Succeed Write</from>
      <to>HadoopInputOutput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHBase evaluation</from>
      <to>Load HBase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>LoadHBase evaluation</from>
      <to>HadoopInputOutput evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopInputOutput Succeed Write</from>
      <to>HBaseInputOutput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopInputOutput Fail Write</from>
      <to>HBaseInputOutput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopInputOutput evaluation</from>
      <to>Hadoop-InputOutput-test</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopInputOutput evaluation</from>
      <to>HBaseInputOutput evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBaseInputOutput Succeed Write</from>
      <to>Hive1Input evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBaseInputOutput Fail Write</from>
      <to>Hive1Input evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBaseInputOutput evaluation</from>
      <to>HBase-InputOutput-test</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HBaseInputOutput evaluation</from>
      <to>Hive1Input evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1-Input Succeed Write</from>
      <to>Hive2Input evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1-Input Fail Write</from>
      <to>Hive2Input evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1Input evaluation</from>
      <to>Hive1-Input</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive1Input evaluation</from>
      <to>Hive2Input evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2-Input Succeed Write</from>
      <to>ImpalaInput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2-Input Fail Write</from>
      <to>ImpalaInput evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2Input evaluation</from>
      <to>Hive2-Input</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Hive2Input evaluation</from>
      <to>ImpalaInput evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>ImpalaInput evaluation</from>
      <to>Impala-Input</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>ImpalaInput evaluation</from>
      <to>AggregatePig evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Impala-Input Succeed Write</from>
      <to>AggregatePig evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Impala-Input Fail Write</from>
      <to>AggregatePig evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig evaluation</from>
      <to>AggregatePig</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig Succeed Write</from>
      <to>HadoopJobExecutor evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig Fail Write</from>
      <to>HadoopJobExecutor evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregatePig evaluation</from>
      <to>HadoopJobExecutor evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor Succeed Write</from>
      <to>AggregateMR evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor Fail Write</from>
      <to>AggregateMR evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor evaluation</from>
      <to>HadoopJobExecutor</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor evaluation</from>
      <to>AggregateMR evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR Succeed Write</from>
      <to>PMR-Hadoop evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR Fail Write</from>
      <to>PMR-Hadoop evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR evaluation</from>
      <to>AggregateMR</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>AggregateMR evaluation</from>
      <to>PMR-Hadoop evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hadoop Succeed Write</from>
      <to>PMR-HBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hadoop Fail Write</from>
      <to>PMR-HBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hadoop evaluation</from>
      <to>PMR - Hadoop</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hadoop evaluation</from>
      <to>PMR-HBase evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - HBase Succeed Write</from>
      <to>PMR-Hive1 evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - HBase Fail Write</from>
      <to>PMR-Hive1 evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-HBase evaluation</from>
      <to>PMR - HBase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-HBase evaluation</from>
      <to>PMR-Hive1 evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive1 Succeed Write</from>
      <to>PMR-Hive2 evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive1 Fail Write</from>
      <to>PMR-Hive2 evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hive1 evaluation</from>
      <to>PMR - Hive1</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hive1 evaluation</from>
      <to>PMR-Hive2 evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hive2 evaluation</from>
      <to>PMR - Hive2</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Hive2 evaluation</from>
      <to>PMR-Impala evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive2 Succeed Write</from>
      <to>PMR-Impala evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Hive2 Fail Write</from>
      <to>PMR-Impala evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Impala Succeed Write</from>
      <to>SqoopImportHDFS evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR - Impala Fail Write</from>
      <to>SqoopImportHDFS evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Impala evaluation</from>
      <to>PMR - Impala</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>PMR-Impala evaluation</from>
      <to>SqoopImportHDFS evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS Succeed Write</from>
      <to>SqoopImportHBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS Fail Write</from>
      <to>SqoopImportHBase evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS evaluation</from>
      <to>SqoopImportHDFS</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS evaluation</from>
      <to>SqoopImportHBase evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase Succeed Write</from>
      <to>SqoopImportHive evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase Fail Write</from>
      <to>SqoopImportHive evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase evaluation</from>
      <to>SqoopImportHBase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBase evaluation</from>
      <to>SqoopImportHive evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive Succeed Write</from>
      <to>SqoopExportHDFS evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive Fail Write</from>
      <to>SqoopExportHDFS evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive evaluation</from>
      <to>SqoopImportHive</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHive evaluation</from>
      <to>SqoopExportHDFS evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS Succeed Write</from>
      <to>Oozie-MapReduce evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS Fail Write</from>
      <to>Oozie-MapReduce evaluation</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS evaluation</from>
      <to>SqoopExportHDFS</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFS evaluation</from>
      <to>Oozie-MapReduce evaluation</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce evaluation</from>
      <to>Oozie-MapReduce</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce evaluation</from>
      <to>DUMMY</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce Succeed Write</from>
      <to>DUMMY</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Oozie-MapReduce Fail Write</from>
      <to>DUMMY</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
  </notepads>
<attributes><group><name>JobRestart</name>
<attribute><key>UniqueConnections</key>
<value>N</value>
</attribute></group></attributes>

</job>
